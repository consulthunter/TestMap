{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-24T18:41:44.641763Z",
     "start_time": "2024-10-24T18:41:10.242905Z"
    }
   },
   "source": [
    "import ast\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, SummarizationPipeline, AutoModelForCausalLM, AutoModelForSeq2SeqLM, BitsAndBytesConfig"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:30:32.893936Z",
     "start_time": "2024-10-07T16:10:26.257833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_files_to_dict(directory):\n",
    "    data_dict = {}\n",
    "    \n",
    "    # Walk through directory and subdirectories\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Check for CSV files\n",
    "            if filename.lower().endswith('.csv'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                \n",
    "                try:\n",
    "                    # Read the file into a DataFrame\n",
    "                    df = pd.read_csv(file_path, sep=',', quotechar=\"'\", low_memory=False)\n",
    "                    # Store DataFrame in the dictionary with the relative file path as the key\n",
    "                    relative_path = os.path.relpath(file_path, directory)\n",
    "                    data_dict[relative_path] = df\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "directory_path = \"F:/Projects/TestMap/TestMap/Output/\"\n",
    "\n",
    "# Read all files and store in dictionary\n",
    "data_dict = read_files_to_dict(directory_path)"
   ],
   "id": "f6c8253c57dbab2d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:31:32.145774Z",
     "start_time": "2024-10-07T16:31:31.261957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combine_csvs(data_dict, keyword):\n",
    "    # Filter DataFrames based on the keyword in the key\n",
    "    filtered_dfs = [df for key, df in data_dict.items() if keyword in key]\n",
    "    \n",
    "    if filtered_dfs:\n",
    "        # Concatenate all filtered DataFrames\n",
    "        combined_df = pd.concat(filtered_dfs, ignore_index=True)\n",
    "        # Write combined DataFrame to a CSV file\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(f\"No files found with keyword '{keyword}'\")\n",
    "        \n",
    "# Combine all CSVs with 'test_method' in the key and write to a single CSV\n",
    "test_methods_df = combine_csvs(data_dict, 'test_methods')\n",
    "\n",
    "# Combine all CSVs with 'test_class' in the key and write to a single CSV\n",
    "test_classes_df = combine_csvs(data_dict, 'test_classes')"
   ],
   "id": "81a2b7ffb4d477e9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initial Formatting",
   "id": "6dbc0b4ae47f9e57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Test Method Formatting\n",
    "\n",
    "The CSV format from CSharp needs to formatted for Python.\n",
    "\n",
    "Test Method records are different than the Test Class records.\n",
    "\n",
    "They need to formatted differently."
   ],
   "id": "d758f80457573d73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Converting Fields to List of Strings\n",
    "\n",
    "Our list of fields from the testing class is separated with `<<SEP>>`."
   ],
   "id": "d91ed0a698e75799"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:31:58.355679Z",
     "start_time": "2024-10-07T16:31:52.224811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_class_fields_to_list(s):\n",
    "    try:\n",
    "        if isinstance(s, str):\n",
    "            s = s.replace(\"<<NEWLINE>>\", \"\\n\")\n",
    "            s = s.replace(\"<<SINGLE-QUOTE>>\", \"\\'\")\n",
    "            temp_list = []\n",
    "            substrs = s.split(\"<<SEP>>\")\n",
    "            \n",
    "            for substr in substrs:\n",
    "                temp_list.append(substr)\n",
    "                \n",
    "            return temp_list\n",
    "        else:\n",
    "            return []\n",
    "        \n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error converting string to list {e}\")\n",
    "        return []\n",
    "\n",
    "# Apply the function to the column\n",
    "test_methods_df['ClassFields'] = test_methods_df['ClassFields'].apply(convert_class_fields_to_list)"
   ],
   "id": "71e33e320d44d06c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Converting Using Statements to List of Strings",
   "id": "f6b742ed86e3ed56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:32:00.793731Z",
     "start_time": "2024-10-07T16:31:58.359684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_usings_to_list(s):\n",
    "    try:\n",
    "        if isinstance(s, str):\n",
    "            s = s.replace(\"<<NEWLINE>>\", \"\\n\")\n",
    "            s = s.replace(\"<<SINGLE-QUOTE>>\", \"\\'\")\n",
    "            temp_list = []\n",
    "            substrs = s.split(\"<<SEP>>\")\n",
    "            \n",
    "            for substr in substrs:\n",
    "                temp_list.append(substr)\n",
    "                \n",
    "            return temp_list\n",
    "        else:\n",
    "            return []\n",
    "        \n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error converting string to list {e}\")\n",
    "        return []\n",
    "\n",
    "# Apply the function to the column\n",
    "test_methods_df['UsingStatements'] = test_methods_df['UsingStatements'].apply(convert_class_fields_to_list)"
   ],
   "id": "a1636932eb68408f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Converting Method Invocations to a List of Tuples\n",
    "\n",
    "When creating the CSV from the original program, we had a list of tuples in CSharp.\n",
    "\n",
    "CSharp doesn't print lists to strings like Python would. \n",
    "\n",
    "So we had to add keywords and special formatting so we\n",
    "could convert to a list that Python would understand."
   ],
   "id": "4ace4389aec7622a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:32:15.397942Z",
     "start_time": "2024-10-07T16:32:00.946185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to add brackets and convert to list of tuples\n",
    "def convert_method_invocations(s):\n",
    "    try:\n",
    "        s = s.replace(\"<<NEWLINE>>\", \"\\n\")\n",
    "        s = s.replace(\"<<SINGLE-QUOTE>>\", \"\\'\")\n",
    "        temp_list = []\n",
    "        substrs = s.split(\"<<SEP>>\")\n",
    "        \n",
    "        for substr in substrs:\n",
    "            substr = substr.lstrip(\"(\").rstrip(\")\")\n",
    "            sub = substr.split('<<TUPLE>>')\n",
    "            if sub[-1] != ' ':\n",
    "                tup = (sub[0].rstrip(', '), sub[-1])\n",
    "                temp_list.append(tup)\n",
    "        return temp_list\n",
    "        \n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error converting string to list of tuples: {e}\")\n",
    "        return []\n",
    "\n",
    "# Apply the function to the column\n",
    "test_methods_df['MethodInvocations'] = test_methods_df['MethodInvocations'].apply(convert_method_invocations)"
   ],
   "id": "1186fc3ed98091c6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Formatting Test Method",
   "id": "f08b20dbe7b54b00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:32:20.580512Z",
     "start_time": "2024-10-07T16:32:15.401948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to add brackets and convert to list of tuples\n",
    "def format_test_method(s):\n",
    "    try:\n",
    "        str = s.replace(\"<<NEWLINE>>\", \"\\n\")\n",
    "        str = str.replace(\"<<SINGLE-QUOTE>>\", \"\\'\")\n",
    "        \n",
    "        return str\n",
    "        \n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error converting string to list of tuples: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Apply the function to the column\n",
    "test_methods_df['MethodBody'] = test_methods_df['MethodBody'].apply(convert_method_invocations)"
   ],
   "id": "234d47c4f3e40569",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test Class Formatting",
   "id": "c30b63a46a3a8da4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Converting Fields to List of Strings\n",
    "\n",
    "Our list of fields from the testing class is separated with `<<SEP>>`."
   ],
   "id": "b2a0a98cd3fbcdce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:32:20.639143Z",
     "start_time": "2024-10-07T16:32:20.605764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_class_fields_to_list(s):\n",
    "    try:\n",
    "        if isinstance(s, str):\n",
    "            s = s.replace(\"<<NEWLINE>>\", \"\\n\")\n",
    "            s = s.replace(\"<<SINGLE-QUOTE>>\", \"\\'\")\n",
    "            temp_list = []\n",
    "            substrs = s.split(\"<<SEP>>\")\n",
    "            \n",
    "            for substr in substrs:\n",
    "                temp_list.append(substr)\n",
    "                \n",
    "            return temp_list\n",
    "        else:\n",
    "            return []\n",
    "        \n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error converting string to list {e}\")\n",
    "        return []\n",
    "\n",
    "# Apply the function to the column\n",
    "test_classes_df['ClassFields'] = test_classes_df['ClassFields'].apply(convert_class_fields_to_list)"
   ],
   "id": "c37dc5e3a31509c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Converting Using Statements to List of Strings",
   "id": "3b3e376f1a91f5dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:32:20.708711Z",
     "start_time": "2024-10-07T16:32:20.666983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_usings_to_list(s):\n",
    "    try:\n",
    "        if isinstance(s, str):\n",
    "            s = s.replace(\"<<NEWLINE>>\", \"\\n\")\n",
    "            s = s.replace(\"<<SINGLE-QUOTE>>\", \"\\'\")\n",
    "            temp_list = []\n",
    "            substrs = s.split(\"<<SEP>>\")\n",
    "            \n",
    "            for substr in substrs:\n",
    "                temp_list.append(substr)\n",
    "                \n",
    "            return temp_list\n",
    "        else:\n",
    "            return []\n",
    "        \n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error converting string to list {e}\")\n",
    "        return []\n",
    "\n",
    "# Apply the function to the column\n",
    "test_classes_df['UsingStatements'] = test_classes_df['UsingStatements'].apply(convert_class_fields_to_list)"
   ],
   "id": "b0a1a4cb7ab18bb1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Format Code",
   "id": "2b5d56e83e7a22e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:38:36.735927Z",
     "start_time": "2024-10-07T16:38:36.044838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to add brackets and convert to list of tuples\n",
    "def format_code(s):\n",
    "    try:\n",
    "        st = s.replace(\"<<NEWLINE>>\", \"\\n\")\n",
    "        st = st.replace(\"<<SINGLE-QUOTE>>\", \"\\'\")\n",
    "\n",
    "        return st\n",
    "        \n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error converting string to list of tuples: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Apply the function to the column\n",
    "test_classes_df['ClassBody'] = test_classes_df['ClassBody'].apply(format_code)\n",
    "test_classes_df['SourceBody'] = test_classes_df['SourceBody'].astype(str).apply(format_code)"
   ],
   "id": "4fda507a94742209",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove Any Empties",
   "id": "6b38f85012c72959"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:38:41.955881Z",
     "start_time": "2024-10-07T16:38:41.441168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_methods_df_filtered = test_methods_df[test_methods_df['MethodInvocations'].apply(lambda x: len(x) > 0)]\n",
    "test_classes_df_filtered = test_classes_df[test_classes_df['SourceBody'].apply(lambda x: len(x) > 0)]"
   ],
   "id": "58d2895099d2d347",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T01:48:13.454452Z",
     "start_time": "2024-10-07T16:38:45.417725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# drop duplicates\n",
    "df_methods_dropped = test_methods_df_filtered.drop_duplicates(subset=['MethodBody'])\n",
    "df_classes_dropped = test_classes_df_filtered.drop_duplicates(subset=['ClassBody'])"
   ],
   "id": "da35bc81b01dea26",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T08:42:01.940497Z",
     "start_time": "2024-10-08T01:48:13.512760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find duplicates based on specific columns\n",
    "test_methods_dup = df_methods_dropped.duplicated(subset=['MethodBody'])\n",
    "test_classes_dup = df_classes_dropped.duplicated(subset=['ClassBody'])\n",
    "\n",
    "# Count the number of duplicate rows based on specified columns\n",
    "num_method_duplicates_based_on_columns = test_methods_dup.sum()\n",
    "num_class_duplicates_based_on_columns = test_classes_dup.sum()\n",
    "\n",
    "\n",
    "print(f\"Number of duplicate rows based on specific columns: {num_method_duplicates_based_on_columns}\")\n",
    "print(f\"Number of duplicate rows based on specific columns: {num_class_duplicates_based_on_columns}\")"
   ],
   "id": "f9fa93ba4e1162f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows based on specific columns: 0\n",
      "Number of duplicate rows based on specific columns: 0\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T08:43:31.807321Z",
     "start_time": "2024-10-08T08:42:02.059872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "df_methods_dropped.to_csv(os.path.join(\"data\", \"test_methods_full.csv\"), index=False)\n",
    "df_classes_dropped.to_csv(os.path.join(\"data\", \"test_classes_full.csv\"), index=False)"
   ],
   "id": "795634192a51d115",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T19:34:21.335563Z",
     "start_time": "2024-09-15T19:34:20.946913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to add brackets and convert to list of tuples\n",
    "def format_code(s):\n",
    "    try:\n",
    "        str = \"// Hello this is a test\"\n",
    "\n",
    "        return str\n",
    "\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error converting string to list of tuples: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# Apply the function to the column\n",
    "df_methods_dropped['MethodBody'] = df_methods_dropped['MethodBody'].apply(format_code)\n",
    "df_classes_dropped['ClassBody'] = df_classes_dropped['ClassBody'].apply(format_code)\n",
    "\n",
    "df_methods_dropped.to_csv(os.path.join(\"data\", \"valid_test_methods_initial.csv\"), index=False)\n",
    "df_classes_dropped.to_csv(os.path.join(\"data\", \"valid_test_classes_initial.csv\"), index=False)"
   ],
   "id": "c68e601d2bd89537",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milit\\AppData\\Local\\Temp\\ipykernel_8000\\1740937196.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_methods_dropped['MethodBody'] = df_methods_dropped['MethodBody'].apply(format_code)\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T16:22:11.741960Z",
     "start_time": "2024-10-23T16:21:27.056680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_test_method_full = pd.read_csv(os.path.join(\"data\", \"test_methods_full.csv\"))\n",
    "df_test_classes_full = pd.read_csv(os.path.join(\"data\", \"test_classes_full.csv\"))"
   ],
   "id": "990a09b4bb85c4a2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Normal Finetune\n",
    "\n",
    "Does the formatting for the typical instruction based finetuning.\n"
   ],
   "id": "d63aa8e06b0e789c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T19:50:42.284024Z",
     "start_time": "2024-10-17T19:50:42.280093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def formatted_prompt(question, answer)-> str:\n",
    "    return f\"<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant:\\n{answer}<|im_end|>\""
   ],
   "id": "ea751eba22d14d6f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Method Level",
   "id": "29b25f36733bd2f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T20:12:13.720988Z",
     "start_time": "2024-10-17T20:12:13.717179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Prompts\n",
    "method_prompts = [\n",
    "    \"Generate a test method for this source code.\",\n",
    "    \"Create a test method to cover this source code.\",\n",
    "    \"Generate a test method to test the functionality of this code.\",\n",
    "    \"Generate a test method based on the following source code.\",\n",
    "    \"Write a test method to validate the behavior of this code.\",\n",
    "]"
   ],
   "id": "4f3fc2b3a5e804d5",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:25:25.486755Z",
     "start_time": "2024-10-18T00:25:25.480974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_method_question(row):\n",
    "    method_invocations = ast.literal_eval(row['MethodInvocations'])\n",
    "    # Joining method and description, discarding if description is missing\n",
    "    source_code = '\\n'.join(\n",
    "        f\"Method: {method}\\nDefinition: {description}\"\n",
    "        for method, description in method_invocations\n",
    "        if description  # This checks if description is not None and not an empty string\n",
    "    )\n",
    "    \n",
    "    # Check if source_code is empty or consists of blank lines\n",
    "    if not source_code.strip():  # strip() removes whitespace\n",
    "        return None\n",
    "    \n",
    "    class_fields = '\\n'.join(ast.literal_eval(row['ClassFields']))\n",
    "    using_statements = '\\n'.join(ast.literal_eval(row['UsingStatements']))\n",
    "    question = f\"\"\"\n",
    "{random.choice(method_prompts)}\n",
    "Here is some contextual information:\n",
    "Source Code and definitions (if any):\n",
    "{source_code}\n",
    "\n",
    "Test Namespace: {row['Namespace']}\n",
    "\n",
    "Test Class Declaration: {row['ClassDeclaration']}\n",
    "\n",
    "Test Class Fields: \n",
    "{class_fields}\n",
    "\n",
    "Test Using Statements: \n",
    "{using_statements}\n",
    "\n",
    "Test Framework: {row['TestFramework']}\n",
    "\n",
    "Language Framework: {row['LanguageFramework']}\n",
    "\n",
    "Please delimit the code with ```\n",
    "    \"\"\"\n",
    "    return question"
   ],
   "id": "750f7b5f86541c69",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:25:30.290189Z",
     "start_time": "2024-10-18T00:25:30.285673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_method_answer(row):\n",
    "    test_code = ast.literal_eval(row['MethodBody'])\n",
    "    answer = f\"\"\"```\n",
    "    {test_code[0][0]}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return answer"
   ],
   "id": "9c42675c750fc521",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:35:35.383301Z",
     "start_time": "2024-10-18T00:33:43.524939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method_instructions = []\n",
    "method_questions = []\n",
    "method_answers = []\n",
    "method_repo = []\n",
    "\n",
    "for index, row in df_test_method_full.iterrows():\n",
    "    question = create_method_question(row)\n",
    "    answer = create_method_answer(row)\n",
    "    if question:\n",
    "        instruction = formatted_prompt(question, answer)\n",
    "        method_questions.append(question)\n",
    "        method_answers.append(answer)\n",
    "        method_instructions.append(instruction)\n",
    "        method_repo.append(row['Repo'])\n",
    "\n",
    "formatted_method_df = pd.DataFrame({\n",
    "    'Instructions': method_instructions,\n",
    "    'Prompt': method_questions,\n",
    "    'Response': method_answers,\n",
    "    'Repo': method_repo\n",
    "})"
   ],
   "id": "97b44c2945f187e6",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:37:02.613927Z",
     "start_time": "2024-10-18T00:37:02.590701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get unique values from 'column1'\n",
    "unique_values = formatted_method_df['Repo'].unique()\n",
    "\n",
    "# Convert to a list if needed\n",
    "unique_values_list = unique_values.tolist()\n",
    "\n",
    "# Calculate the number of unique values\n",
    "num_unique = len(unique_values)\n",
    "\n",
    "# Calculate 5% of the number of unique values\n",
    "subset_size = max(1, int(num_unique * 0.20))  # Ensure at least one item\n",
    "\n",
    "# Select a random subset of unique values\n",
    "random_subset = random.sample(list(unique_values), subset_size)"
   ],
   "id": "bd171372504e0ece",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:37:04.809300Z",
     "start_time": "2024-10-18T00:37:04.753866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create two DataFrames\n",
    "formatted_method_df_valid = formatted_method_df[formatted_method_df['Repo'].isin(random_subset)]  # DataFrame with selected subset\n",
    "formatted_method_df_train = formatted_method_df[~formatted_method_df['Repo'].isin(random_subset)]  "
   ],
   "id": "bfc2a26785450335",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:46:10.069852Z",
     "start_time": "2024-10-18T00:45:42.680921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "formatted_method_train_dataset = Dataset.from_pandas(formatted_method_df_train)\n",
    "formatted_method_valid_dataset = Dataset.from_pandas(formatted_method_df_valid)\n",
    "original_method_dataset = Dataset.from_pandas(df_test_method_full)"
   ],
   "id": "1cbc0ce546c4ee9",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:49:55.987071Z",
     "start_time": "2024-10-18T00:46:29.043162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Upload to huggingface\n",
    "# upload originals\n",
    "test_method_original_name = \"Distaste1194/csharp_test_methods_original\"\n",
    "original_method_dataset.push_to_hub(test_method_original_name, private=True)\n",
    "\n",
    "# upload formatted\n",
    "test_method_train = \"Distaste1194/csharp_test_methods_formatted_training\"\n",
    "formatted_method_train_dataset.push_to_hub(test_method_train, private=True)\n",
    "\n",
    "# validation_set\n",
    "test_method_valid = \"Distaste1194/csharp_test_methods_formatted_validation\"\n",
    "formatted_method_valid_dataset.push_to_hub(test_method_valid, private=True)"
   ],
   "id": "937c282ed1566c3e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9dbdd63c525407f8dc082daa49459ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/108 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22575eebc1a44030a2d50f985c4b7d60"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/108 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c699e5846c54e69bc02f1724f169d53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/108 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "756493d9bad048bd992e0b5de1e10006"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/108 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50eb1e46c1ee49908597115236dcc2cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/108 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5dad48f810a54ff2afc7715b40df2a46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/108 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18b4cea756c344dc951668cb2c9ede47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42dc2510c97f4cd2857d50c87bf69a58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/109 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "132c38351b5f4647a660ee2497d04537"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/109 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8254dd5eccb9461dabe32ad1a4f287c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/109 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f44ec1cf88d49998d00e86a9c3989fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0da3e84c971451c8336b6409f10bb4a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/65 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ccd912219ff44e796e56b0c4da139de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Distaste1194/csharp_test_methods_formatted_validation/commit/2fbf4fd3f3041bb7ef12061abfbf1770d69f5839', commit_message='Upload dataset', commit_description='', oid='2fbf4fd3f3041bb7ef12061abfbf1770d69f5839', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Distaste1194/csharp_test_methods_formatted_validation', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Distaste1194/csharp_test_methods_formatted_validation'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Class Level",
   "id": "3d4ed69aa49d84db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:57:09.705461Z",
     "start_time": "2024-10-18T00:57:09.701229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Prompts\n",
    "class_prompts = [\n",
    "    \"Generate a test class for this source code.\",\n",
    "    \"Create a test class to cover this source code.\",\n",
    "    \"Generate a test class to test the functionality of this code.\",\n",
    "    \"Generate a test class based on the following source code.\",\n",
    "    \"Write a test class to validate the behavior of this code.\",\n",
    "]"
   ],
   "id": "be90d2370d647c71",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:57:07.705411Z",
     "start_time": "2024-10-18T00:57:07.700505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_class_question(row):\n",
    "    source_code = row['SourceBody']\n",
    "    \n",
    "    class_fields = '\\n'.join(ast.literal_eval(row['ClassFields']))\n",
    "    using_statements = '\\n'.join(ast.literal_eval(row['UsingStatements']))\n",
    "    question = f\"\"\"\n",
    "{random.choice(class_prompts)}\n",
    "Here is some contextual information:\n",
    "Source Code Class:\n",
    "{source_code}\n",
    "\n",
    "Test Namespace: {row['Namespace']}\n",
    "\n",
    "Test Class Declaration: {row['ClassDeclaration']}\n",
    "\n",
    "Test Class Fields: \n",
    "{class_fields}\n",
    "\n",
    "Test Using Statements: \n",
    "{using_statements}\n",
    "\n",
    "Test Framework: {row['TestFramework']}\n",
    "\n",
    "Language Framework: {row['LanguageFramework']}\n",
    "\n",
    "Please delimit the code with ```\n",
    "    \"\"\"\n",
    "    return question"
   ],
   "id": "126a1bfe0ec3788e",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:57:12.431389Z",
     "start_time": "2024-10-18T00:57:12.428352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_class_answer(row):\n",
    "    test_code = row['ClassBody']\n",
    "    answer = f\"\"\"```\n",
    "    {test_code}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return answer"
   ],
   "id": "be2f692984086e2d",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:57:16.305924Z",
     "start_time": "2024-10-18T00:57:14.290621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_instructions = []\n",
    "class_repo = []\n",
    "for index, row in df_test_classes_full.iterrows():\n",
    "    question = create_class_question(row)\n",
    "    answer = create_class_answer(row)\n",
    "    if question:\n",
    "        instruction = formatted_prompt(question, answer)\n",
    "        class_instructions.append(instruction)\n",
    "        class_repo.append(row['Repo'])\n",
    "\n",
    "formatted_class_df = pd.DataFrame({\n",
    "    'Instructions': class_instructions,\n",
    "    'Repo': class_repo\n",
    "})"
   ],
   "id": "3f21baee092f0986",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:57:39.437768Z",
     "start_time": "2024-10-18T00:57:39.432475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get unique values from 'column1'\n",
    "unique_values = formatted_class_df['Repo'].unique()\n",
    "\n",
    "# Convert to a list if needed\n",
    "unique_values_list = unique_values.tolist()\n",
    "\n",
    "# Calculate the number of unique values\n",
    "num_unique = len(unique_values)\n",
    "\n",
    "# Calculate 5% of the number of unique values\n",
    "subset_size = max(1, int(num_unique * 0.20))  # Ensure at least one item\n",
    "\n",
    "# Select a random subset of unique values\n",
    "random_subset = random.sample(list(unique_values), subset_size)"
   ],
   "id": "229d2304fada5a57",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T01:00:12.236894Z",
     "start_time": "2024-10-18T01:00:11.930728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create two DataFrames\n",
    "formatted_class_df_valid = formatted_class_df[formatted_class_df['Repo'].isin(random_subset)]  # DataFrame with selected subset\n",
    "formatted_class_df_train = formatted_class_df[~formatted_class_df['Repo'].isin(random_subset)]  "
   ],
   "id": "bf8585cb737089d3",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T01:02:11.937301Z",
     "start_time": "2024-10-18T01:02:09.837886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "formatted_class_train_dataset = Dataset.from_pandas(formatted_class_df_train)\n",
    "formatted_class_valid_dataset = Dataset.from_pandas(formatted_class_df_valid)\n",
    "original_class_dataset = Dataset.from_pandas(df_test_classes_full)"
   ],
   "id": "33c2236a5d37b717",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T01:02:56.707727Z",
     "start_time": "2024-10-18T01:02:13.045947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Upload to huggingface\n",
    "# upload originals\n",
    "test_class_original_name = \"Distaste1194/csharp_test_classes_original\"\n",
    "original_class_dataset.push_to_hub(test_class_original_name, private=True)\n",
    "\n",
    "# upload formatted\n",
    "test_class_train = \"Distaste1194/csharp_test_classes_formatted_training\"\n",
    "formatted_class_train_dataset.push_to_hub(test_class_train, private=True)\n",
    "\n",
    "# validation_set\n",
    "test_class_valid = \"Distaste1194/csharp_test_classes_formatted_validation\"\n",
    "formatted_class_valid_dataset.push_to_hub(test_class_valid, private=True)"
   ],
   "id": "458f258507915a74",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "234209e4d5504a48a0ddcbc5dfef64e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/15 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3659d218ab1b4e54be4c983db31ec36c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8990b23cc4c744a88ce5447f94639d35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/13 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ae999ea5a354977971348a857e4a1d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d1535bab67343c2939d4ce90e9dfbfd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47d0a348cf08458196a12ccafefaed0e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Distaste1194/csharp_test_classes_formatted_validation/commit/618acbda044b6bf1619d210a739774417f8ad707', commit_message='Upload dataset', commit_description='', oid='618acbda044b6bf1619d210a739774417f8ad707', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Distaste1194/csharp_test_classes_formatted_validation', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Distaste1194/csharp_test_classes_formatted_validation'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Retrieval Augmented Generation",
   "id": "226fab717e37f53d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Method Level",
   "id": "7c0355e0c771470"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T19:34:21.502166Z",
     "start_time": "2024-09-15T19:34:21.499141Z"
    }
   },
   "cell_type": "code",
   "source": "## Prompts",
   "id": "f45e90114336e4d8",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Class Level",
   "id": "eac618de42394b04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T19:34:21.557239Z",
     "start_time": "2024-09-15T19:34:21.554140Z"
    }
   },
   "cell_type": "code",
   "source": "## Prompts",
   "id": "38059929cf18d865",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Chain-of-thoughts Finetune",
   "id": "a93f7d929e1058ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Method Level",
   "id": "74d73fe07f665e80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T19:34:21.609950Z",
     "start_time": "2024-09-15T19:34:21.607252Z"
    }
   },
   "cell_type": "code",
   "source": "## Prompts",
   "id": "61e750709eec7af",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Class Level",
   "id": "1f0ba742e78481ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T19:34:21.729951Z",
     "start_time": "2024-09-15T19:34:21.727158Z"
    }
   },
   "cell_type": "code",
   "source": "## Prompts",
   "id": "1fbdb5345033c6b9",
   "outputs": [],
   "execution_count": 123
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
